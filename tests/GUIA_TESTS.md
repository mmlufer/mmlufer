# ğŸ“˜ GuÃ­a para OrganizaciÃ³n de Tests

Esta guÃ­a establece las convenciones a seguir para la organizaciÃ³n y escritura de tests en el proyecto.

## ğŸ“ Estructura de Directorios

```
/tests/                        # Directorio raÃ­z para TODOS los tests
â”‚
â”œâ”€â”€ unit/                     # Tests unitarios
â”‚   â”œâ”€â”€ test_module1.py
â”‚   â””â”€â”€ test_module2.py
â”‚
â”œâ”€â”€ integration/              # Tests de integraciÃ³n
â”‚   â”œâ”€â”€ test_feature1.py
â”‚   â””â”€â”€ test_feature2.py
â”‚
â”œâ”€â”€ conftest.py               # Fixtures compartidas entre tests
â”œâ”€â”€ run_tests.py              # Herramienta para ejecutar tests
â””â”€â”€ pytest.ini                # ConfiguraciÃ³n de pytest
```

## âš ï¸ Reglas Importantes

### 1. UbicaciÃ³n de Tests

- âœ… **CORRECTO**: Todos los tests deben ubicarse EXCLUSIVAMENTE dentro del directorio `/tests`
- âŒ **INCORRECTO**: NO crear tests dentro de `/src` o sus subdirectorios

```
# âœ… CORRECTO
/tests/unit/test_filesystem.py

# âŒ INCORRECTO
/src/mcp/servers/filesystem/tests/test_filesystem.py
/src/mcp/servers/filesystem/test_filesystem.py
```

### 2. Nomenclatura

- Los archivos de tests deben nombrarse con el prefijo `test_`
- Las funciones de test deben seguir el patrÃ³n `test_[funciÃ³n]_[escenario]_[resultado_esperado]`

```python
# âœ… CORRECTO
def test_read_file_nonexistent_raises_error():
    ...

# âŒ INCORRECTO
def verify_read_file():
    ...
```

## ğŸ§ª Tipos de Tests

### Tests Unitarios (`/tests/unit/`)

- Prueban unidades individuales de cÃ³digo (funciones, mÃ©todos)
- No tienen dependencias externas (usan mocks/stubs)
- RÃ¡pidos de ejecutar
- Usar marcador `@pytest.mark.unit`

### Tests de IntegraciÃ³n (`/tests/integration/`)

- Prueban interacciones entre componentes
- Pueden utilizar recursos externos controlados
- Requieren mÃ¡s configuraciÃ³n
- Usar marcador `@pytest.mark.integration`

## ğŸ”„ Estructura AAA

Todos los tests deben seguir la estructura Arrange-Act-Assert:

```python
def test_example():
    # Arrange - Preparar el entorno y datos
    server = FilesystemServer(['/ruta/permitida'])
    test_file = '/ruta/permitida/archivo.txt'

    # Act - Ejecutar la acciÃ³n a probar
    result = server.read_file(test_file)

    # Assert - Verificar el resultado
    assert result == 'contenido esperado'
```

## ğŸ› ï¸ Fixtures y ConfiguraciÃ³n

- Usar `conftest.py` para definir fixtures compartidas entre tests
- Preferir fixtures de pytest sobre setUp/tearDown
- Especificar el alcance de las fixtures:
  - `@pytest.fixture`: por defecto, se ejecuta para cada test
  - `@pytest.fixture(scope="module")`: se ejecuta una vez por mÃ³dulo
  - `@pytest.fixture(scope="session")`: se ejecuta una vez por sesiÃ³n

## ğŸ“‹ Checklist de Calidad

AsegÃºrese de que todos los tests:

- [ ] EstÃ¡n ubicados correctamente en el directorio `/tests`
- [ ] Siguen la convenciÃ³n de nomenclatura adecuada
- [ ] Son independientes entre sÃ­
- [ ] Incluyen casos normales, casos de error y casos lÃ­mite
- [ ] No contienen secretos o credenciales
- [ ] Son deterministas (siempre dan el mismo resultado para los mismos inputs)
- [ ] Se limpian despuÃ©s de su ejecuciÃ³n

## ğŸ” Buenas PrÃ¡cticas Adicionales

1. **ParametrizaciÃ³n**: Usar `@pytest.mark.parametrize` para probar mÃºltiples casos
2. **Mocks**: Aislar el cÃ³digo de sus dependencias
3. **CategorizaciÃ³n**: Usar marcadores para organizar tests por tipo o velocidad
4. **Claridad**: Preferir claridad sobre brevedad en el cÃ³digo de test

## ğŸ“Š Cobertura

La meta es mantener una cobertura de cÃ³digo superior al 80%, con Ã©nfasis en cubrir:
- Todos los caminos de ejecuciÃ³n
- Todas las ramas condicionales
- Todos los bloques de manejo de errores

Para verificar la cobertura:

```bash
pytest --cov=src/mcp tests/
```

---

Consulte tambiÃ©n la regla `@mejores_practicas-tests-cursor-rules` para mÃ¡s detalles.
